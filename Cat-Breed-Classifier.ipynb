{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/karenliu/miniconda2/envs/ai/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.python.keras import applications\n",
    "from tensorflow.python.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.python.keras.models import Model, Sequential\n",
    "from tensorflow.python.keras.layers import Flatten, Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dimensions of our images.\n",
    "img_width, img_height = 150, 150\n",
    "\n",
    "top_model_weights_path = 'bottleneck_fc_weights.h5'\n",
    "top_model_path = 'bottleneck_fc_model.h5'\n",
    "train_data_dir = 'data/training'\n",
    "validation_data_dir = 'data/validation'\n",
    "nb_train_samples = 480\n",
    "nb_validation_samples = 120\n",
    "epochs = 5\n",
    "batch_size = 4\n",
    "class_indices = None\n",
    "\n",
    "def save_bottlebeck_features():\n",
    "    global class_indices\n",
    "    datagen = ImageDataGenerator(\n",
    "        rescale=1. / 255,\n",
    "        horizontal_flip=True,\n",
    "        width_shift_range=0.10,\n",
    "        rotation_range=20)\n",
    "\n",
    "    # build the VGG16 network\n",
    "    model = applications.VGG16(include_top=False, weights='imagenet')\n",
    "\n",
    "    generator = datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        shuffle=False)\n",
    "    \n",
    "    if not class_indices:\n",
    "        class_indices = generator.class_indices\n",
    "    print('Generator class_indices: ', generator.class_indices)\n",
    "    #bottleneck_features_train = model.predict_generator(generator, nb_train_samples // batch_size)\n",
    "    #np.save(open('bottleneck_features_train.npy', 'wb'), bottleneck_features_train)\n",
    "    target_batches = nb_train_samples // batch_size\n",
    "    X_validation = np.zeros(shape=(target_batches*batch_size, 4, 4, 512))\n",
    "    Y_validation = np.zeros(shape=(target_batches*batch_size, generator.num_class))\n",
    "    batches = 0\n",
    "    for x_batch, y_batch in generator:\n",
    "        bottleneck_features = model.predict_on_batch(x_batch)\n",
    "        #print('bottleneck_features shape: ', bottleneck_features.shape)\n",
    "        X_validation[batches*batch_size:(batches+1)*batch_size] = bottleneck_features\n",
    "        Y_validation[batches*batch_size:(batches+1)*batch_size] = y_batch\n",
    "        batches += 1\n",
    "        if batches >= target_batches:\n",
    "            break\n",
    "\n",
    "    print('Training Bottleneck: ', np.shape(X_validation), np.shape(Y_validation))\n",
    "    np.savez(open('bottleneck_features_train.npy', 'wb'), X=X_validation, Y=Y_validation)\n",
    "\n",
    "    ## Generating Validation Bottleneck features\n",
    "    generator = datagen.flow_from_directory(\n",
    "        validation_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        shuffle=False)\n",
    "    #bottleneck_features_validation = model.predict_generator(generator, nb_validation_samples // batch_size)\n",
    "    #np.savez(open('bottleneck_features_validation.npy', 'wb'), bottleneck_features_validation)\n",
    "    target_batches = nb_validation_samples // batch_size\n",
    "    X_validation = np.zeros(shape=(target_batches*batch_size, 4, 4, 512))\n",
    "    Y_validation = np.zeros(shape=(target_batches*batch_size, generator.num_class))\n",
    "    batches = 0\n",
    "    for x_batch, y_batch in generator:\n",
    "        bottleneck_validation = model.predict_on_batch(x_batch)\n",
    "        #print('bottleneck_validation shape: ', bottleneck_validation.shape)\n",
    "        X_validation[batches*batch_size:(batches+1)*batch_size] = bottleneck_validation\n",
    "        Y_validation[batches*batch_size:(batches+1)*batch_size] = y_batch\n",
    "        batches += 1\n",
    "        if batches >= target_batches:\n",
    "            break\n",
    "\n",
    "    print('Validation Bottleneck: ', np.shape(X_validation), np.shape(Y_validation))\n",
    "    np.savez(open('bottleneck_features_validation.npy', 'wb'), X=X_validation, Y=Y_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 48 images belonging to 3 classes.\n",
      "Generator class_indices:  {'JapaneseBobtail': 0, 'Mainecoon': 1, 'Ragdoll': 2}\n",
      "Training Bottleneck:  (480, 4, 4, 512) (480, 3)\n",
      "Found 12 images belonging to 3 classes.\n",
      "Validation Bottleneck:  (120, 4, 4, 512) (120, 3)\n"
     ]
    }
   ],
   "source": [
    "save_bottlebeck_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120, 4, 4, 512)\n",
      "(120, 3)\n"
     ]
    }
   ],
   "source": [
    "def load_bottleneck_features():\n",
    "    features = np.load(open('bottleneck_features_validation.npy', 'rb'))\n",
    "    print(features['X'].shape)\n",
    "    print(features['Y'].shape)\n",
    "    \n",
    "load_bottleneck_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_classes = 3\n",
    "def train_top_model():\n",
    "    train_arrays = np.load(open('bottleneck_features_train.npy', 'rb'))\n",
    "    #train_labels = np.array([0] * (int(nb_train_samples / 2)) + [1] * (int(nb_train_samples / 2)))\n",
    "    train_data = train_arrays['X']\n",
    "    train_labels = train_arrays['Y']\n",
    "    \n",
    "    validation_arrays = np.load(open('bottleneck_features_validation.npy', 'rb'))\n",
    "    #validation_labels = np.array([0] * (int(nb_validation_samples / 2)) + [1] * (int(nb_validation_samples / 2)))\n",
    "    validation_data = validation_arrays['X']\n",
    "    validation_labels = validation_arrays['Y']\n",
    "\n",
    "    model = Sequential() # tf.keras.models.Sequential()\n",
    "    model.add(Flatten(input_shape=train_data.shape[1:]))\n",
    "    model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dropout(0.5))\n",
    "    model.add(tf.keras.layers.Dense(model_classes, activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer='rmsprop',\n",
    "                  loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    model.fit(train_data, train_labels,\n",
    "              epochs=epochs,\n",
    "              batch_size=batch_size,\n",
    "              validation_data=(validation_data, validation_labels))\n",
    "    model.save_weights(top_model_weights_path)\n",
    "    model.save(top_model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 480 samples, validate on 120 samples\n",
      "Epoch 1/10\n",
      "480/480 [==============================] - 4s - loss: 0.7516 - acc: 0.8479 - val_loss: 0.1527 - val_acc: 0.9417\n",
      "Epoch 2/10\n",
      "480/480 [==============================] - 4s - loss: 0.0748 - acc: 0.9729 - val_loss: 0.0490 - val_acc: 0.9917\n",
      "Epoch 3/10\n",
      "480/480 [==============================] - 3s - loss: 0.0589 - acc: 0.9813 - val_loss: 0.0669 - val_acc: 0.9583\n",
      "Epoch 4/10\n",
      "480/480 [==============================] - 3s - loss: 0.0573 - acc: 0.9854 - val_loss: 0.0757 - val_acc: 0.9667\n",
      "Epoch 5/10\n",
      "480/480 [==============================] - 3s - loss: 0.0587 - acc: 0.9896 - val_loss: 0.2863 - val_acc: 0.9000\n",
      "Epoch 6/10\n",
      "480/480 [==============================] - 3s - loss: 0.0081 - acc: 0.9958 - val_loss: 0.4459 - val_acc: 0.9167\n",
      "Epoch 7/10\n",
      "480/480 [==============================] - 3s - loss: 0.0041 - acc: 0.9979 - val_loss: 0.2070 - val_acc: 0.9333\n",
      "Epoch 8/10\n",
      "480/480 [==============================] - 3s - loss: 9.6884e-04 - acc: 1.0000 - val_loss: 0.5218 - val_acc: 0.8917\n",
      "Epoch 9/10\n",
      "480/480 [==============================] - 3s - loss: 1.4430e-04 - acc: 1.0000 - val_loss: 0.0868 - val_acc: 0.9583\n",
      "Epoch 10/10\n",
      "480/480 [==============================] - 4s - loss: 0.0299 - acc: 0.9917 - val_loss: 0.1069 - val_acc: 0.9500\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "train_top_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.models import load_model\n",
    "from PIL import Image as pil_image\n",
    "\n",
    "# build the VGG16 network\n",
    "vgg_model = applications.VGG16(include_top=False, weights='imagenet')\n",
    "def calculate_bottleneck_for_testing(img_path, model, rescale=1. / 255):\n",
    "    image_shape = (img_width, img_height, 3)\n",
    "    img = pil_image.open(img_path)\n",
    "    img = img.resize((img_width, img_height))\n",
    "    x = np.asarray(img, dtype=float)\n",
    "    x = x * rescale\n",
    "    X = np.zeros(shape=(1, img_width, img_height, 3))\n",
    "    X[0] = x\n",
    "    bottleneck_features = model.predict_on_batch(X)\n",
    "    return bottleneck_features\n",
    "\n",
    "loaded_model = load_model(top_model_path)\n",
    "def predict_breed(cat_img, kera_model):\n",
    "    bottleneck_test = calculate_bottleneck_for_testing(cat_img, vgg_model)\n",
    "    X_test = np.zeros(shape=(1, 4, 4, 512))\n",
    "    X_test[0] = bottleneck_test\n",
    "    return kera_model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Out Classifier With This Cat Image:\n",
    "<img src=\"data/test/cat2.jpg\",width=150,height=150>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class_indices:  {'JapaneseBobtail': 0, 'Mainecoon': 1, 'Ragdoll': 2}\n",
      "[[  6.37534662e-14   1.55650205e-13   1.00000000e+00]]\n",
      "[[  3.12105112e-04   8.99790964e-10   9.99687910e-01]]\n"
     ]
    }
   ],
   "source": [
    "print('class_indices: ', class_indices)\n",
    "\n",
    "#result = predict_breed('data/test/Ragdoll/ragdoll0001.jpg', loaded_model)\n",
    "#print(result)\n",
    "\n",
    "#print(predict_breed('data/training/Ragdoll/ragdoll0016.jpg', loaded_model))\n",
    "print(predict_breed('data/test/cat2.jpg', loaded_model))\n",
    "\n",
    "print(predict_breed('data/test/Cat.jpg', loaded_model))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
